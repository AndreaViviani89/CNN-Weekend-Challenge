{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:36.517152Z","iopub.status.busy":"2022-06-04T02:15:36.516689Z","iopub.status.idle":"2022-06-04T02:15:36.527368Z","shell.execute_reply":"2022-06-04T02:15:36.526187Z","shell.execute_reply.started":"2022-06-04T02:15:36.517119Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","torch.manual_seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["# DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:37.125836Z","iopub.status.busy":"2022-06-04T02:15:37.124326Z","iopub.status.idle":"2022-06-04T02:15:39.947352Z","shell.execute_reply":"2022-06-04T02:15:39.946185Z","shell.execute_reply.started":"2022-06-04T02:15:37.125786Z"},"trusted":true},"outputs":[],"source":["# Define a transform to normalize the data (Preprocessing) and cast to tensor\n","   \n","train_transform = transforms.Compose([\n","                                    transforms.Resize((150,150)),\n","#                                     \n","                                    transforms.RandomRotation(20),\n","                                    transforms.RandomResizedCrop(size=124),\n","                                    transforms.RandomHorizontalFlip(),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize(\n","                                        mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]) \n","                                    ])\n","    \n","    \n","test_transform = transforms.Compose([\n","                                        transforms.Resize((150,150)),\n","                                        transforms.CenterCrop(124),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(\n","                                            mean=[0.485, 0.456, 0.406],\n","                                            std=[0.229, 0.224, 0.225])\n","        \n","                                    ])\n","\n","\n","\n","root_dir = '../input/intel-image-classification/' \n","# Load the training data\n","trainset = datasets.ImageFolder(root_dir+'/seg_train/seg_train', transform = train_transform)\n","trainloader = DataLoader(trainset, batch_size=64, shuffle = True)\n","\n","\n","# Load the test data\n","testset = datasets.ImageFolder(root_dir + '/seg_test/seg_test',transform=test_transform)\n","testloader = DataLoader(testset, batch_size=64, shuffle=False)\n","\n","\n","print(trainloader.dataset, '\\n')\n","print(testloader.dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:39.950344Z","iopub.status.busy":"2022-06-04T02:15:39.949635Z","iopub.status.idle":"2022-06-04T02:15:40.156707Z","shell.execute_reply":"2022-06-04T02:15:40.155583Z","shell.execute_reply.started":"2022-06-04T02:15:39.950288Z"},"trusted":true},"outputs":[],"source":["images, labels = iter(trainloader).next()\n","print(f'image size: {images[0].shape}')\n","trainset.classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:40.159177Z","iopub.status.busy":"2022-06-04T02:15:40.158495Z","iopub.status.idle":"2022-06-04T02:15:41.095188Z","shell.execute_reply":"2022-06-04T02:15:41.094196Z","shell.execute_reply.started":"2022-06-04T02:15:40.159128Z"},"trusted":true},"outputs":[],"source":["inv_normalize =  transforms.Normalize(\n","    mean=-1*np.divide([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n","    std=1/np.array([0.229, 0.224, 0.225])\n",")\n","\n","def class_plot(data , classes ,inv_normalize = None,n_figures = 12):\n","    n_row = int(n_figures/4)\n","    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n","    for ax in axes.flatten():\n","        idx = np.random.randint(len(data))\n","        image,label = data[idx]\n","        label = int(label)\n","        l = classes[label]\n","        if(inv_normalize!=None):\n","            image = inv_normalize(image)\n","        image = image.numpy().transpose(1,2,0)\n","        im = ax.imshow(image)\n","        ax.set_title(l)\n","        ax.axis('off')\n","    plt.show()\n","class_plot(trainset,trainset.classes,inv_normalize);"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:41.098115Z","iopub.status.busy":"2022-06-04T02:15:41.097549Z","iopub.status.idle":"2022-06-04T02:15:41.63796Z","shell.execute_reply":"2022-06-04T02:15:41.636951Z","shell.execute_reply.started":"2022-06-04T02:15:41.09806Z"},"trusted":true},"outputs":[],"source":["model = models.resnext50_32x4d(pretrained = True)\n","\n","# freezing paramaters\n","# n_parameters = 0\n","# for param in model.parameters():\n","#     param.requires_grad = False\n","\n","inputs = model.fc.in_features\n","outputs = len(trainset.classes)\n","# model.fc = nn.Linear(inputs, outputs)\n","clf = nn.Sequential(\n","              nn.Dropout(0.30), \n","              nn.Linear(inputs, outputs)\n","                  )\n","\n","model.fc = clf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:41.640126Z","iopub.status.busy":"2022-06-04T02:15:41.639619Z","iopub.status.idle":"2022-06-04T02:15:41.743109Z","shell.execute_reply":"2022-06-04T02:15:41.74183Z","shell.execute_reply.started":"2022-06-04T02:15:41.640067Z"},"trusted":true},"outputs":[],"source":["# Test\n","model(images[0].unsqueeze(0)).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Training and validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:41.745592Z","iopub.status.busy":"2022-06-04T02:15:41.745015Z","iopub.status.idle":"2022-06-04T02:15:41.753574Z","shell.execute_reply":"2022-06-04T02:15:41.752472Z","shell.execute_reply.started":"2022-06-04T02:15:41.745544Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-04T02:15:41.756331Z","iopub.status.busy":"2022-06-04T02:15:41.755525Z","iopub.status.idle":"2022-06-04T03:07:25.654326Z","shell.execute_reply":"2022-06-04T03:07:25.650236Z","shell.execute_reply.started":"2022-06-04T02:15:41.756281Z"},"trusted":true},"outputs":[],"source":["model.to(device)\n","learning_rate = 0.001\n","epochs = 30\n","\n","optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","train_losses = []\n","test_losses = []\n","train_accuracies = []\n","test_accuracies = []\n","benchmark_accuracy = 0.90\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    running_accuracy = 0\n","    running_loss = 0\n","    # training\n","    for x_train_batch, y_train_batch in trainloader:\n","        x_train_batch = x_train_batch.to(device)\n","        y_train_batch = y_train_batch.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        logits = model(x_train_batch)\n","        train_preds = torch.argmax(logits.detach(), dim=1)\n","\n","        # loss\n","        train_loss = criterion(logits, y_train_batch)\n","        running_loss += train_loss.item()\n","\n","        # train accuracy\n","        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n","        running_accuracy += train_acc.item()\n","\n","        # backward pass\n","        \n","        train_loss.backward()\n","        \n","        # update paramaters\n","        \n","        optimizer.step()\n","\n","    # mean loss (all batches losses divided by the total number of batches)\n","    train_losses.append(running_loss / len(trainloader))\n","    \n","    # mean accuracies\n","    train_accuracies.append(running_accuracy / len(trainloader))\n","    \n","    # print\n","    print(f'Train loss: {train_losses[-1] :.4f}')\n","\n","    # validation\n","    model.eval()\n","    with torch.no_grad():\n","        running_accuracy = 0\n","        running_loss = 0\n","\n","        for x_test_batch, y_test_batch in testloader:\n","            x_test_batch = x_test_batch.to(device)\n","            y_test_batch = y_test_batch.to(device)\n","            # logits\n","            test_logits = model(\n","                x_test_batch)\n","\n","            # predictions\n","            test_preds = torch.argmax(test_logits, dim=1)\n","            \n","            # accuracy\n","            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n","            running_accuracy += test_acc.item()\n","\n","            # loss\n","            test_loss = criterion(test_logits, y_test_batch)\n","            running_loss += test_loss.item()\n","\n","        # mean accuracy for each epoch\n","        test_accuracies.append(running_accuracy / len(testloader))\n","\n","        # mean loss for each epoch\n","        test_losses.append(running_accuracy / len(testloader))\n","        # print\n","        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n","        print('='*100)\n","        # saving best model\n","        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n","        if test_accuracies[-1] > benchmark_accuracy:\n","            # save model to cpu\n","            torch.save(model.to('cpu').state_dict(), './model.pth')\n","            model.to(device) # bring back to gpu\n","\n","            # update benckmark\n","            benchmark_accuracy = test_accuracies[-1]\n","\n","    model.train()\n","\n","\n","# Plots\n","x_epochs = list(range(epochs))\n","plt.figure(figsize=(15, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(x_epochs, train_losses, marker='o', label='train')\n","plt.plot(x_epochs, test_losses, marker='o', label='test')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(x_epochs, train_accuracies, marker='o', label='train')\n","plt.plot(x_epochs, test_accuracies, marker='o', label='test')\n","plt.axhline(benchmark_accuracy, c='grey', ls='--',\n","            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.savefig('./learning_curve.png', dpi = 200)\n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
